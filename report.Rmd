---
title: Multiple Linear Regression Analysis of NBA Player Salaries
author: "Yizhe Zhao, Valentyn Lytvyniuk, Cyre Beroncal, Shi Wang, and Jack Zhang"
date: "`r Sys.Date()`"
output:
 bookdown::pdf_document2:
   extra_dependencies: ["float"]
bibliography: ["citations.bib"]
biblio-style: "apa"
csl: "apa-no-ampersand"
link-citations: true
---

```{r setup, message=FALSE, results="hide", include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, results="hide", message=FALSE,
                      cache=TRUE, fig.pos = "H", out.extra = "")
if(!require("GGally")) install.packages("GGally")
if(!require("kableExtra")) install.packages("kableExtra")
if(!require("cowplot")) install.packages("cowplot")
if(!require("ggfortify")) install.packages("ggfortify")
if(!require("car")) install.packages("car")
library("car")
library("GGally")
library("ggfortify")
library("kableExtra")
library("cowplot")
library("knitr")
library("MASS")
library("forcats")
library("bookdown")
library("readr")
library("dplyr")
library("patchwork")
ggplot2::theme_set(theme_minimal())
ggplot2::theme_update(plot.title = element_text(hjust = 0.5, size = 11))
```

\newpage

# Introduction

An athlete’s earnings in professional sports are influenced by factors beyond their raw performance.
Physicality, popularity, and basketball IQ meet in the NBA. A player’s salary can vary based on what they do on the court, how they promote themselves, the position they play, and the terms of their contract.
This project aims to understand the relationship between NBA player salaries and a player’s pure, on-court contributions, using statistical techniques to identify the main factors behind any changes in player pay.

While the common assumption is that performance drives earnings, modern professional sports organizations now operate at the intersection of entertainment and profit. 
This means that, along with more obvious statistics like scoring, playmaking, and defense, team role, fame, and how much a player is worth are also taken into account. 
As a result, our central research question arises as such: "To what extent can NBA player salary be explained by on-court performance and position? What is the relationship between salary, and statistics such as points per game, fouls per game, assists per game, steals per game, and position?"

Linear regression is an appropriate statistical tool for this analysis because we are interested in estimating the average change in salary associated with unit changes in predictor variables (points per game, assists). The method allows us to quantify the effect of each variable while holding others constant. Additionally, categorical predictors such as a player's main position can be incorporated, enabling the model to account for role-based differences in compensation.

By interpreting the linear regression model parameters, it would allow us to understand both player valuation (in terms of their performance) and the patterns that shape the NBA labor market. Could it be, for instance, that certain positions on the court inherently compensated greater, regardless of how successful a player is? Does a player’s earnings better correlate with points or assists than with defensive stats? Such inquiries are important for teams sorting through their salary allocations, players negotiating salaries and those analyzing the fairness of pay scales.

# Data Description

## Data Source

The dataset analyzed here was constructed by Davide Ratto [@ratto_nba_2019], combining statistics from several sources available through a Milan-based university project. Data from websites basketball-reference.com [@noauthor_basketball_nodate], hoopshype.com [@hoopshype_hoopshype_nodate], and a Kaggle repository [@gift_social_2017] were combined to build this dataset. The objective of the initial study was to create forecasts for player selection to the All-Star Game using a combination of data on performance and popularity. Only the most recent season’s data was kept for each player to preserve a sample that operators of the datasets consider independent.

In the model, we use Salary (USD) as the response variable to investigate which aspects of player performance and role most correlate to NBA compensation.

## Variables

We're analyzing the response variable, players' Salary (Figure \@ref(fig:vars).A) with these predictors:

- Points Per Game (PTS): Measures a player's scoring ability and offensive productivity (Figure \@ref(fig:vars).B)
- Personal Fouls Per Game (PF): Reflective of a player’s defensive discipline and quality (Figure \@ref(fig:vars).C)
- Assists Per Game (AST): Reflects offensive role and playmaking contributions (Figure \@ref(fig:vars).D)
- Steals Per Game (STL): Indicator of defensive activity and quality (Figure \@ref(fig:vars).E)
- Main Position (Pos1: [PG, SG, SF, PF, C]): A categorical variable that reflects role on court

```{r clean}
nba <- read.csv("nba.csv")
nba <- nba |>
  filter(Salary>1e5) # |>
  # mutate(Salary = Salary / 1e6) # change unit to salary in millions
write.csv(nba, file = "nba_cleaned.csv")
```

```{r vars, fig.cap='Density histograms of response variables and predictors'}
n <- nrow(nba)
get_scott <- function(x) {
  result <- pretty(range(x), n = nclass.scott(x), min.n = 1)
  return(result)
}
nba.hist <- list() 
nba.hist$Salary <- ggplot(nba) +
  geom_histogram(aes(Salary, y = after_stat(density)), 
                 breaks = get_scott(nba$Salary)) +
  geom_density(aes(Salary)) +
  # labs(title = "Salary\nDensity Histogram") +
  labs(x = "Salary (USD)")

nba.hist$PTS <- ggplot(nba) +
  geom_histogram(aes(PTS, y = after_stat(density)), 
                 breaks = get_scott(nba$PTS)) +
  geom_density(aes(PTS)) +
  # labs(title = "Points Per Game\nDensity Histogram") +
  labs(x = "Points per game (PTS)")

nba.hist$PF <- ggplot(nba) +
  geom_histogram(aes(PF, y = after_stat(density)),
                 breaks = get_scott(nba$PF)) +
  geom_density(aes(PF)) +
  # labs(title = "Personal Fouls per game\nDensity Histogram") +
  labs(x = "Personal Fouls (PF)")

nba.hist$AST <- ggplot(nba) +
  geom_histogram(aes(AST, y = after_stat(density)),
                 breaks = get_scott(nba$AST)) +
  geom_density(aes(AST)) +
  # labs(title = "Assists per game\nDensity Histogram") +
  labs(x = "Assists (AST)")

nba.hist$STL <- ggplot(nba) +
  geom_histogram(aes(STL, y = after_stat(density)), 
                 breaks = get_scott(nba$STL)) +
  geom_density(aes(STL)) +
  # labs(title = "Steals per game\nDensity Histogram") +
  labs(x = "Steals per game (STL)")

plot_grid(plotlist = nba.hist, labels = "AUTO")

```

## Variable Summaries

```{r scatter-matrix, fig.cap="Scatterplot matrix of respoonse and continuous predictors", fig.height=3.5}
ggpairs(nba,
        columns = c("PTS", "PF", "AST", "STL", "Salary"))
```

We have filtered out players with missing salary information.

Final row of Figure \@ref(fig:scatter-matrix) shows that the response variable (Salary) is roughly linear in the 4 continuous predictor variables. We theorize that the model, Equation \@ref(eq:lm), would be a good linear approximation.
\begin{equation}
Salary = \beta_0 + \beta_1\ PTS + \beta_2\ PF + \beta_3\ AST + \beta_4\ STL + \beta_5\ I(PF) + \beta_6\ I(PG) + \beta_7\ I(SF) + \beta_8\ I(SG) + \varepsilon
(\#eq:lm)
\end{equation}


```{r box-plots, fig.cap="Box Plots of Salary against categorical dummy variables", fig.height=3}
ggplot(nba) +
  geom_boxplot(aes(x = Salary, y = Pos1)) +
  labs(x = "Salary (USD)", y = "Player Position (Pos1)")
```

# Preliminary Results

## Residual Analysis

```{r lin-model}
nba <- nba |>
  # change the team name into categorical levels
  mutate(Pos1 = factor(Pos1))
nba_model <- lm(Salary ~ PTS + PF + AST + STL + Pos1, data=nba)
```

```{r diagnostic-1, fig.cap = "Diagnostic Plots", fig.height=3.5}
summary(nba_model)
autoplot(nba_model, which=c(1, 2))
```

```{r diagnostic-2, fig.cap = "Diagnostic Plots, continued", fig.height=4}
graph_summaries_2 <- function(model){
  p3 <- ggplot(model) +
    geom_point(aes(x = .fitted, y = model$model[[model_response_variables(model)]])) +
    labs(x = "Fitted Values") +
    labs(y = "Salary (USD)") +
    geom_abline(color = "royalblue") +
    labs(title = "Response vs. Fitted")
  p4 <- ggplot(model) +
    geom_histogram(aes(x = rstandard(model), y = after_stat(density)), 
                   breaks = get_scott(rstandard(model))) +
    geom_density(aes(x = rstandard(model)),
                 colour = "royalblue") +
    stat_function(fun = dnorm, linetype = "dotted") +
    theme(plot.title = element_text(hjust = 0.5)) +
    labs(title = "Standarized Residuals Histogram") +
    labs(x = "Standardized Residuals") +
    labs(y = "Density")
  p3 + p4
}
graph_summaries_2(nba_model)
```

We notice a few signs that our model violates linear regression assumptions. The residual vs. fitted graph (Figure \@ref(fig:diagnostic-1), left) has a pattern, which indicates that the residuals (and therefore errors) are correlated. It also contains points with uneven spread, which indicates heteroscedasticity (i.e. non-constant variance of errors). From the same graph, since the expected value of the residuals is not 0 across the range, non-linearity of our model is also apparent, i.e. Equation \@ref(eq:lm) does not hold.

The model also violates the *normality of error* assumption. The normal-QQ plot (Figure \@ref(fig:diagnostic-1), right) contains points above the identity line from +1 standard deviation and above. The standardized residuals histogram (Figure \@ref(fig:diagnostic-2), right) also shows a long right-tail (right-skewed). This means our model tends to underestimate player salaries at higher salary ranges.

The scatter plot of response vs. fitted values (Figure \@ref(fig:diagnostic-2), left) also suggest that our model is not reliable for predicting salary in terms of the predictors we defined.

## Model Discussion

```{r prelim-model, fig.cap = "Prelimiary estimation of model parameters", results='markup'}

apd <- sprintf("$\\\\hat{\\\\beta_%d}$", seq(from = 0, to = 8))
est_table <- bind_rows(coef(nba_model))
kable(est_table, format = "latex", booktabs = TRUE, escape = FALSE, caption = "Prelimiary estimation of model parameters.") |>
  kable_styling(latex_options = "hold_position") |>
  add_header_above(apd, escape = FALSE)
```

Because of the violations mentioned above, the interpretations we can make are limited. With that in mind, these still estimates tell us that player performance is correlated with their salary, which is also affected by their on-court positions.

In particular, we notice from the estimated model parameters (as seen in Table \@ref(tab:prelim-model)) that the predictor, assists (AST), contribute to the average salary by about \$1.1 million ($\hat{\beta_3} \approx 1.09$) for each unit increase while holding all other predictors constant. Personal fouls (PF) has an opposite effect ($\hat{\beta_2} \approx -0.90$).

For the categorical variables, we expect the average player salary to increase by about \$2.8 million ($\hat{\beta_5} \approx 2.83$) if they change position from shooting guard or power forward (the reference level, SG+PF) to Centre (C), holding all other predictors constant.

# Model Selection

## Transformations

```{r variable-transformation}
nba <- nba |>
  mutate(tSalary = log(Salary),
         tPTS = sqrt(PTS),
         tAST = log(AST + (quantile(AST, 0.25)/quantile(AST, 0.25))^2),
         tSTL = log(STL + (quantile(STL, 0.25)/quantile(STL, 0.25))^2),
         tPF = log(PF + (quantile(PF, 0.25)/quantile(PF, 0.25))^2),
         Pos1 = relevel(Pos1, "SF"),
         tPos1 = fct_collapse(Pos1, "SF+PF" = c("SF", "PF")),
         tPos1 = relevel(tPos1, "SF+PF"))
```

We chose the log-transform for the Salary response variable to fix the violation of non-constant variance assumption, 
and a mix of log and square/cube root transformations for the predictor variables to fix violation of linearity assumption. For log-transform of predictor variables, a small constant (square of the first quartile divided by the third quartile of each predictor) is added to avoid taking the log of 0 [@muldoon_log_0_2018].

Model \@ref(eq:transformed) (omitting the constant mentioned above for brevity) is specified as
\begin{equation}
\begin{split}
log(Salary) = \beta_0 &+ \beta_1\ \sqrt{PTS} + \beta_2\ log(PFoul) + \beta_3\ log(AST) + \beta_4\ log(STL) \\
&+ \beta_5\ I(PForward) + \beta_6\ I(PG) + \beta_7\ I(SF) + \beta_8\ I(SG) + \varepsilon
(\#eq:transformed)
\end{split}
\end{equation}
Its associated diagnostic plots are included below in Figure \@ref(fig:diagnostic-transformed). While violations of non-constant variance, linearity, and normality of errors are still present in the plots, they are significantly improved compared to the original model, and are approximately satisfied to the degree to reasonably allow us to use partial F-tests to eliminate predictors.

```{r diagnostic-transformed, fig.cap = "Model with transformed response and predictors."}
mod.transformed <- lm(tSalary ~ tPTS + tAST + tSTL + tPF + Pos1, data=nba)
autoplot(mod.transformed, which = c(1, 2))
```

## Partial F-test

```{r reduced-model}
mod.reduced <- lm(tSalary ~ tPTS + tAST + tPos1, data=nba)
anova(mod.reduced, mod.transformed)
```

We propose reduced model
\begin{equation}
\begin{split}
log(Salary) = \beta_0 &+ \beta_1\ \sqrt{PTS} + \beta_2\ log(AST) \\
&+ \beta_3\ I(SF+PF) + \beta_4\ I(PG) + \beta_5\ I(SG) + \varepsilon
(\#eq:reduced)
\end{split}
\end{equation}
which removes the transformed STL and PF predictors, as well as collapsing SF and PF categorical levels into the same level. The choices in these predictors are inspired by the R summary output of the model (which we will omit here), where the p-value for the t-test for each individual predictor's coefficient are high. A partial F-test with model \@ref(eq:reduced) as $H_0$, and the transformed full model \@ref(eq:transformed) above as $H_1$ gives us a p-value of 0.267 **[INSERT ANOVA TABLE HERE]**, which is large enough to indicates that the reduced model should be used, even with linear regression assumptions only approximately satisfied.

## Problematic Observations

```{r leverage, fig.cap="Plot of leverage and standardized residuals against index."}
get_infl_measures <- function(model) {
  p <<- length(model$coefficients)
  n <<- nrow(model$model)
  result.df <- influence.measures(model)$infmat |> as.data.frame()
  result.df <- result.df |>
    mutate(index = as.numeric(row.names(result.df)),
           sresid = rstandard(model))
  return(result.df)
}
graph_obs <- function(df) {
  p1 <- ggplot(df) +
    geom_linerange(aes(x = index, ymin = 0, ymax = hat)) +
    geom_hline(aes(yintercept= 2 * (p + 1) / n), colour = "royalblue", linetype = "dashed") +
    labs(title = "Leverage vs Index", x= "i", y = expression(h[ii]))
  p2 <- ggplot(df) +
    geom_point(aes(x = index, y = sresid)) +
    labs(title = "Standardized Residuals vs Index", x = "i", y = expression(r[i]))
  plot_grid(p1, p2, labels = "AUTO")
}
mod.inflences <- get_infl_measures(mod.reduced)
graph_obs(mod.inflences)
```

Figure \@ref(fig:leverage).B does not show any $|r_i| > 4$ ($n=$ `r toString(n)` large enough to use 4 as cutoff), so we don't have any outliers in our current model.

From Figure \@ref(fig:leverage).A, there are leverage points in the dataset, where the blue line is the $h = \frac{2(p+1)}{n}$ cutoff. Since we do not have any outliers, all leverage points are good leverage points, so we will check influential measures using Cook's distance and DFFITS next.

```{r influential, fig.cap="Cook's distance against index."}
graph_inf <- function(df) {
  cook_cutoff <<- qf(0.5, p+1, n-p-1)
  p1 <- ggplot(df) +
    geom_linerange(aes(x = index, ymin = 0, ymax = cook.d)) +
    geom_hline(aes(yintercept = 4 / n), colour = "royalblue", linetype = "dashed") +
    labs(title = "Cook's Distance vs Index", x= "i", y = expression(D[i]))
  p2 <- ggplot(df) +
    geom_point(aes(x = index, y = dffit)) +
    geom_hline(aes(yintercept = 2 * sqrt((p+1)/n)), colour = "royalblue", linetype = "dashed") +
    geom_hline(aes(yintercept = -2 * sqrt((p+1)/n)), colour = "royalblue", linetype = "dashed") +
    labs(title = "DFFITS vs Index", x = "i", y = expression(DFFITS[i]))
  plot_grid(p1, p2, labels = "AUTO")
}
# manually inspect the influential data points
mod.inflences <-
  mod.inflences |>
  # create an indicator column for if any of the dfbeta measures for each beta is greater than 2/sqrt(n)
  # the second argument to if_any is a lambda function since the argument requires type function
  mutate(over.dfbetas = if_any(starts_with("dfb."), ~ .x > 2/sqrt(n)))
infl_df <- nba |>
  mutate(over.cook.4.n = mod.inflences$cook.d > 4/n,
         over.dffits = abs(mod.inflences$dffit) > 2 * sqrt((p+1)/n),
         over.dfbetas = mod.inflences$over.dfbetas) |>
  slice(which(over.cook.4.n | over.dffits | over.dfbetas))
graph_inf(mod.inflences)
```

Figure \@ref(fig:influential) shows that the dataset has no influential points using Cook's cutoff ($F_{0.5,\ p+1,\ n-p-1} =$ `r toString(round(cook_cutoff, 3))`), but has `r infl_df |> filter(over.cook.4.n) |> nrow() |> toString()` influential points using a different cutoff ($\frac{4}{n}$ = `r toString(round(4/n), 3)`). Alternatively, the DFFITS measure shows `r infl_df |> filter(over.dffits) |> nrow() |> toString()` influential points.

Manually inspecting these points do not reveal any invalid data values for all predictors before or after transformations, so they can't be removed based on invalid data criteria. 

# Final Model Inference and Results

# Discussion and Conclusion

# Author Contributions

Yizhe Zhao

- Rmd code used to analyze data and generate the plots, as well as the formatting for outputting the final report pdf from Rmd
- Preliminary model results section of the report

Shi Wang

- Formatting, rewriting, citations, and general proofreading of the report

Valentyn Lytvyniuk

- Proofreading, organizing in-person meeting, co-writing introduction and data description, collaborating on the data set and response/predictor variable selection

Cyre Beroncal

- Wrote initial drafts of introduction and data description sections, proposed research question
- Collaborated in selecting and interpreting initial variables used in relation to regression outputs

Jack Zhang

- Assisted in selecting and evaluating potential datasets for analysis
- Wrote the notes in the Group Teamwork Agreement Doc
- Proofreading to ensure clarity and accuracy


# Bibliography
