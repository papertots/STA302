---
title: Multiple Linear Regression Analysis of NBA Player Salaries
author: "Yizhe Zhao, Valentyn Lytvyniuk, Cyre Beroncal, Shi Wang, and Jack Zhang"
date: "`r Sys.Date()`"
output:
 bookdown::pdf_document2:
#   extra_dependencies: ["float", "booktabs"]
bibliography: ["citations.bib"]
biblio-style: "apa"
csl: "apa-no-ampersand"
link-citations: true
header-includes:
  - \setlength{\parindent}{1em}
  - \setlength{\parskip}{0em}
---

```{r setup, message=FALSE, results="hide", include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, results="hide", message=FALSE,
                      cache= T, fig.pos = "H", out.extra = "")
if(!require("GGally")) install.packages("GGally")
if(!require("kableExtra")) install.packages("kableExtra")
if(!require("cowplot")) install.packages("cowplot")
if(!require("ggfortify")) install.packages("ggfortify")
if(!require("car")) install.packages("car")
if(!require("gtsummary")) install.packages("gtsummary")
library("labelled")
library("gtsummary")
library("car")
library("GGally")
library("ggfortify")
library("kableExtra")
library("cowplot")
library("MASS")
library("forcats")
library("bookdown")
library("dplyr")
library("patchwork")
ggplot2::theme_set(theme_minimal())
ggplot2::theme_update(plot.title = element_text(hjust = 0.5, size = 11))
```

\newpage

# Introduction

An athlete’s earnings in professional sports are influenced by factors beyond their raw performance.
Physicality, popularity, and basketball IQ meet in the NBA. A player’s salary can vary based on what they do on the court, how they promote themselves, the position they play, and the terms of their contract.
This project aims to understand the relationship between NBA player salaries and a player’s pure, on-court contributions, using statistical techniques to identify the main factors behind any changes in player pay.

While the common assumption is that performance drives earnings, modern professional sports organizations now operate at the intersection of entertainment and profit. 
This means that, along with more obvious statistics like scoring, playmaking, and defense, team role, fame, and how much a player is worth are also taken into account. 
As a result, our central research question arises as such: "To what extent can NBA player salary be explained by on-court performance and position? What is the relationship between salary, and statistics such as points per game, fouls per game, assists per game, steals per game, and position?"

Linear regression is an appropriate statistical tool for this analysis because we are interested in estimating the average change in salary associated with unit changes in predictor variables (points per game, assists). The method allows us to quantify the effect of each variable while holding others constant. Additionally, categorical predictors such as a player's main position can be incorporated, enabling the model to account for role-based differences in compensation.

By interpreting the linear regression model parameters, it would allow us to understand both player valuation (in terms of their performance) and the patterns that shape the NBA labour market. Could it be, for instance, that certain positions on the court inherently compensated greater, regardless of how successful a player is? Does a player’s earnings better correlate with points or assists than with defensive stats? Such inquiries are important for teams sorting through their salary allocations, players negotiating salaries and those analyzing the fairness of pay scales.

\newpage

# Data Description

## Data Source

The dataset analyzed here was constructed by Davide Ratto [@ratto_nba_2019], combining statistics from several sources available through a Milan-based university project. Data from websites basketball-reference.com [@noauthor_basketball_nodate], hoopshype.com [@hoopshype_hoopshype_nodate], and a Kaggle repository [@gift_social_2017] were combined to build this dataset. The objective of the initial study was to create forecasts for player selection to the All-Star Game using a combination of data on performance and popularity. Only the most recent season’s data was kept for each player to preserve a sample that operators of the datasets consider independent.

In the model, we use Salary (USD millions) as the response variable to investigate which aspects of player performance and role most correlate to NBA compensation, since it's a continuous and non-negative variable that reflects NBA compensation, making it suitable in linear regression.

## Variables

We're analyzing the response variable, players' Salary (Figure \@ref(fig:vars).A) with these predictors:

- Points Per Game (PTS): Measures a player's scoring ability and offensive productivity (Figure \@ref(fig:vars).B)
- Personal Fouls Per Game (PF): Reflective of a player’s defensive discipline and quality (Figure \@ref(fig:vars).C)
- Assists Per Game (AST): Reflects offensive role and playmaking contributions (Figure \@ref(fig:vars).D)
- Steals Per Game (STL): Indicator of defensive activity and quality (Figure \@ref(fig:vars).E)
- Main Position (Pos1: [PG, SG, SF, PF, C]): A categorical variable that reflects role on court

```{r clean}
nba <- read.csv("nba.csv")
nba <- nba |>
  filter(Salary > 1e5)
write.csv(nba, file = "nba_cleaned.csv")
```

```{r vars, fig.cap='Density histograms of response variables and predictors'}
n <- nrow(nba)
get_scott <- function(x) {
  result <- pretty(range(x), n = nclass.scott(x), min.n = 1)
  return(result)
}
nba.hist <- list() 
nba.hist$Salary <- ggplot(nba) +
  geom_histogram(aes(Salary, y = after_stat(density)), 
                 breaks = get_scott(nba$Salary)) +
  geom_density(aes(Salary)) +
  labs(x = "Salary (USD)")

nba.hist$PTS <- ggplot(nba) +
  geom_histogram(aes(PTS, y = after_stat(density)), 
                 breaks = get_scott(nba$PTS)) +
  geom_density(aes(PTS)) +
  labs(x = "Points per game (PTS)")

nba.hist$PF <- ggplot(nba) +
  geom_histogram(aes(PF, y = after_stat(density)),
                 breaks = get_scott(nba$PF)) +
  geom_density(aes(PF)) +
  labs(x = "Personal Fouls (PF)")

nba.hist$AST <- ggplot(nba) +
  geom_histogram(aes(AST, y = after_stat(density)),
                 breaks = get_scott(nba$AST)) +
  geom_density(aes(AST)) +
  labs(x = "Assists (AST)")

nba.hist$STL <- ggplot(nba) +
  geom_histogram(aes(STL, y = after_stat(density)), 
                 breaks = get_scott(nba$STL)) +
  geom_density(aes(STL)) +
  labs(x = "Steals per game (STL)")

plot_grid(plotlist = nba.hist, labels = "AUTO")
```

## Variable Summaries

```{r var-labels}
nba <- nba |>
  set_variable_labels(
    Salary = "Salary (USD)",
    PTS = "Points",
    AST = "Assists",
    PF = "Personal fouls",
    STL = "Steals",
    Pos1 = "Position on Court"
)
```

```{r scatter-matrix, fig.cap="Scatterplot matrix of respoonse and continuous predictors", fig.height=3.5}
ggpairs(nba,
        columns = c("PTS", "PF", "AST", "STL", "Salary"))
```

We have filtered out players with missing salary information.

Final row of Figure \@ref(fig:scatter-matrix) shows that the response variable (Salary) is roughly linear in the 4 continuous predictor variables. We theorize that the model, Equation \@ref(eq:lm), would be a good linear approximation.
\begin{equation}
Salary = \beta_0 + \beta_1\ PTS + \beta_2\ PF + \beta_3\ AST + \beta_4\ STL + \beta_5\ I(PF) + \beta_6\ I(PG) + \beta_7\ I(SF) + \beta_8\ I(SG) + \varepsilon
(\#eq:lm)
\end{equation}


```{r box-plots, fig.cap="Box Plots of Salary against categorical dummy variables", fig.height=3}
ggplot(nba) +
  geom_boxplot(aes(x = Salary, y = Pos1)) +
  labs(x = "Salary (USD)", y = "Player Position (Pos1)")
```

\newpage

# Preliminary Results

## Residual Analysis

```{r lin-model}
nba <- nba |>
  # change the team name into categorical levels
  mutate(Pos1 = factor(Pos1))
nba_model <- lm(Salary ~ PTS + PF + AST + STL + Pos1, data=nba)
```

```{r diagnostic-1, fig.cap = "Diagnostic Plots", fig.height=3.5}
summary(nba_model)
autoplot(nba_model, which=c(1, 2))
```

```{r diagnostic-2, fig.cap = "Diagnostic Plots, continued", fig.height=4}
graph_summaries_2 <- function(model){
  p3 <- ggplot(model) +
    geom_point(aes(x = .fitted, y = model$model[[model_response_variables(model)]])) +
    labs(x = "Fitted Values") +
    labs(y = "Salary (USD)") +
    geom_abline(color = "royalblue") +
    labs(title = "Response vs. Fitted")
  p4 <- ggplot(model) +
    geom_histogram(aes(x = rstandard(model), y = after_stat(density)), 
                   breaks = get_scott(rstandard(model))) +
    geom_density(aes(x = rstandard(model)),
                 colour = "royalblue") +
    stat_function(fun = dnorm, linetype = "dotted") +
    theme(plot.title = element_text(hjust = 0.5)) +
    labs(title = "Standarized Residuals Histogram") +
    labs(x = "Standardized Residuals") +
    labs(y = "Density")
  p3 + p4
}
graph_summaries_2(nba_model)
```

We notice a few signs that our model violates linear regression assumptions. The residual vs. fitted graph (Figure \@ref(fig:diagnostic-1), left) has a pattern, which indicates that the residuals (and therefore errors) are correlated. It also contains points with uneven spread, which indicates heteroscedasticity (i.e. non-constant variance of errors). From the same graph, since the expected value of the residuals is not 0 across the range, non-linearity of our model is also apparent, i.e. Equation \@ref(eq:lm) does not hold.

The model also violates the *normality of error* assumption. The normal-QQ plot (Figure \@ref(fig:diagnostic-1), right) contains points above the identity line from +1 standard deviation and above. The standardized residuals histogram (Figure \@ref(fig:diagnostic-2), right) also shows a long right-tail (right-skewed). This means our model tends to underestimate player salaries at higher salary ranges.

The scatter plot of response vs. fitted values (Figure \@ref(fig:diagnostic-2), left) also suggest that our model is not reliable for predicting salary in terms of the predictors we defined.

## Model Discussion

```{r prelim-model, fig.cap = "Prelimiary estimation of model parameters", results='markup'}

apd <- sprintf("$\\\\hat{\\\\beta_%d}$", seq(from = 0, to = 8))
est_table <- bind_rows(coef(nba_model))
kable(est_table, format = "latex", booktabs = TRUE, escape = FALSE, caption = "Prelimiary estimation of model parameters.") |>
  kable_styling(latex_options = "hold_position") |>
  add_header_above(apd, escape = FALSE)
```

Because of the violations mentioned above, the interpretations we can make are limited. With that in mind, these still estimates tell us that player performance is correlated with their salary, which is also affected by their on-court positions.

In particular, we notice from the estimated model parameters (as seen in Table \@ref(tab:prelim-model)) that the predictor, assists (AST), contribute to the average salary by about \$1.2 million ($\hat{\beta_3} \approx `r nba_model[["coefficients"]]["AST"] |> round(-3)`$) for each unit increase while holding all other predictors constant. Personal fouls (PF) has an opposite effect ($\hat{\beta_2} \approx `r nba_model[["coefficients"]]["PF"] |> round(-3)`$).

For the categorical variables, we expect the average player salary to decrease by about \$4 million ($\hat{\beta_5} \approx `r nba_model[["coefficients"]]["Pos1SG"] |> round(-3)`$) if they change position from center (the reference level, C) to shooting guard (SG), holding all other predictors constant.

\newpage

# Model Selection

## Transformations

```{r variable-transformation}
nba <- nba |>
  mutate(tSalary = log(Salary),
         tPTS = sqrt(PTS),
         tAST = log(AST + (quantile(AST, 0.25)/quantile(AST, 0.25))^2),
         tSTL = log(STL + (quantile(STL, 0.25)/quantile(STL, 0.25))^2),
         tPF = log(PF + (quantile(PF, 0.25)/quantile(PF, 0.25))^2),
         Pos1 = relevel(Pos1, "SF"),
         tPos1 = fct_collapse(Pos1, "SF+PF" = c("SF", "PF")),
         tPos1 = relevel(tPos1, "SF+PF")) |>
  # rename levels
  mutate(tPos1 = fct_recode(tPos1,
                            "Forwards" = "SF+PF",
                            "Center" = "C",
                            "Shooting Guard" = "SG",
                            "Point Guard" = "PG"))
nba <- nba |>
  set_variable_labels(
    tPTS = "$\\sqrt{\\text{Points}}$",
    tAST = "$log($Assists$)$",
    tSTL = "$log($Steals$)$",
    tPF = "$log($Personal Fouls$)$",
    tPos1 = "Position on Court"
)
```

We chose the log-transform for the Salary response variable to fix the violation of non-constant variance assumption, 
and a mix of log and square/cube root transformations for the predictor variables to fix violation of linearity assumption. For log-transform of predictor variables, a small constant (square of the first quartile divided by the third quartile of each predictor) is added to avoid taking the log of 0 [@muldoon_log-0_2018].
While this would slightly change the sampling distribution of the corresponding $\hat{\beta}_{LE}$, it should remain close enough to the true distribution to not drastically affect our confidence interval calculation for our large dataset [@muldoon_log-0_2018].

Model \@ref(eq:transformed) (omitting the constant mentioned above for brevity) is specified as
\begin{equation}
\begin{split}
log(Salary) = \beta_0 &+ \beta_1\ \sqrt{PTS} + \beta_2\ log(PFoul) + \beta_3\ log(AST) + \beta_4\ log(STL) \\
&+ \beta_5\ I(PForward) + \beta_6\ I(PG) + \beta_7\ I(SF) + \beta_8\ I(SG) + \varepsilon
(\#eq:transformed)
\end{split}
\end{equation}
Its associated diagnostic plots are included below in Figure \@ref(fig:diagnostic-transformed). While violations of non-constant variance, linearity, and normality of errors are still present in the plots, they are significantly improved compared to the original model, and are approximately satisfied to the degree to reasonably allow us to use partial F-tests to eliminate predictors. It is reasonable since F-test is considered *robust* against violations of normality of error and constant variance specifically [@berger_experimental_2018].

```{r diagnostic-transformed, fig.cap = "Model with transformed response and predictors.", fig.height=3}
mod.transformed <- lm(tSalary ~ tPTS + tAST + tSTL + tPF + Pos1, data=nba)
autoplot(mod.transformed, which = c(1, 2))
```

## Partial F-test

```{r reduced-model}
mod.reduced <- lm(tSalary ~ tPTS + tAST + tPos1, data=nba)
anova(mod.reduced, mod.transformed)
```

We propose reduced model
\begin{equation}
\begin{split}
log(Salary) = \beta_0 &+ \beta_1\ \sqrt{PTS} + \beta_2\ log(AST) \\
&+ \beta_3\ I(C) + \beta_4\ I(PG) + \beta_5\ I(SG) + \varepsilon
(\#eq:reduced)
\end{split}
\end{equation}
which removes the transformed STL and PF predictors, as well as collapsing SF and PF categorical levels into the same level.
The choices in these predictors are inspired by the R summary output of the fitted model (which we will omit here),
where the p-value for the t-test for each individual predictor's coefficient are high.
A partial F-test with model \@ref(eq:reduced) as $H_0$,
and the transformed full model \@ref(eq:transformed) above as $H_1$ gives us a p-value of 0.267,
which is large enough to indicates that the reduced model should be used.

## Additional Predictors

```{r var-additional, fig.cap="Distribution of the additional predictors.", fig.height=2.5}
nba <- nba |> mutate(tFvot = log(Fvot))
var_label(nba$tFvot) <- "$log($Fan Votes$)$"
nba.hist$tFvot <- ggplot(nba) +
  geom_histogram(aes(tFvot, y = after_stat(density)),
                 breaks = get_scott(nba$tFvot)) +
  geom_density(aes(tFvot)) +
  labs(x = "log(Fan Votes)")
nba.hist$Age <- ggplot(nba) +
  geom_histogram(aes(Age, y = after_stat(density)),
                 breaks = get_scott(nba$Age)) +
  geom_density(aes(Age))
plot_grid(nba.hist$tFvot, nba.hist$Age, labels = "AUTO")
```

```{r diagnostic-additional, fig.cap="Diagnostic of the new fitted model after incorporating additional predictors.", fig.height=2.5}
mod.additional <- lm(formula = tSalary ~ tPTS + tAST + tFvot + Age + tPos1, data = nba)
autoplot(mod.additional, which = c(1,2))
```

```{r diagnostic-additional-cont, fig.cap="Diagnostic plots, continued.", fig.height=2.5}
graph_summaries_2(mod.additional)
```

Because the project requires 5 predictors, we needed to include 2 additional predictors. We propose adding $log(\text{Fan Votes})$ and Age to incorporate popularity and seniority measures.

Figure \@ref(fig:var-additional) shows their distribution,
and Figure \@ref(fig:diagnostic-additional)+\@ref(fig:diagnostic-additional-cont) shows that
there are no major regression assumptions violations for the updated Model \@ref(eq:additional),
similar to what we saw earlier in Figure \@ref(fig:diagnostic-transformed).
Specifically, while the blue mean line in Figure \@ref(fig:diagnostic-additional) (left) is not completely straight and the data plot is not the null plot, it's close enough to a constant of zero to approximately satisfy the assumption of linearity.
The spread of points around 0 is also approximately the same and therefore approximately satisfy the constant variation of error assumption.
In Figure \@ref(fig:diagnostic-additional) (right), the distribution of standardized residuals is slightly left-skewed, but it's close enough to normality that most of our analysis (F-tests and confidence intervals) still hold by robustness of ANOVA F-test and central limit theorem (with $n=$ `r nrow(mod.additional$model)`), respectively.
\begin{equation}
\begin{split}
log(Salary) = \beta_0 &+ \beta_1\ \sqrt{PTS} + \beta_2\ log(AST) + \beta_3 log(FVot) \\
&+ \beta_4 Age + \beta_5\ I(C) + \beta_6\ I(PG) + \beta_7\ I(SG) + \varepsilon
(\#eq:additional)
\end{split}
\end{equation}

```{r additional-measures}
anova(mod.reduced, mod.additional)
vif(mod.additional)
```

A partial F test gives us a very significant p-value of $2.2\times 10^{-16}$, while each estimated coefficient has a variance inflation factor $<5$,
therefore we decide to use this as our final model for analysis.

## Problematic Observations

```{r leverage, fig.cap="Plot of leverage and standardized residuals against index."}
get_infl_measures <- function(model) {
  p <<- length(model$coefficients)
  n <<- nrow(model$model)
  result.df <- influence.measures(model)$infmat |>
    as.data.frame()
  result.df |>
    mutate(index = as.numeric(row.names(result.df)),
           sresid = rstandard(model))
}
graph_obs <- function(df) {
  p1 <- ggplot(df) +
    geom_linerange(aes(x = index, ymin = 0, ymax = hat)) +
    geom_hline(aes(yintercept= 2 * (p + 1) / n), colour = "royalblue", linetype = "dashed") +
    labs(title = "Leverage vs Index", x= "i", y = expression(h[ii]))
  p2 <- ggplot(df) +
    geom_point(aes(x = index, y = sresid)) +
    labs(title = "Standardized Residuals vs Index", x = "i", y = expression(r[i]))
  plot_grid(p1, p2, labels = "AUTO")
}
mod.influences <- get_infl_measures(mod.additional)
graph_obs(mod.influences)
```

Figure \@ref(fig:leverage).B only shows 1 data point whose $|r_i| > 4$ ($n= `r toString(n)`$ large enough to use 4 as cutoff), so we only have 1 outliers in our current model.

From Figure \@ref(fig:leverage).A, there are leverage points in the dataset, where the blue line is the $h = \frac{2(p+1)}{n}$ cutoff. Since we only have 1 outlier, all but one of our leverage points are good leverage points, so we will check influential measures using Cook's distance, DFFITS, and DFBETAS measurements next.

```{r influential, fig.cap="Cook's distance against index."}
cook_cutoff <- qf(0.5, p+1, n-p-1)
graph_inf <- function(df) {
  p1 <- ggplot(df) +
    geom_linerange(aes(x = index, ymin = 0, ymax = cook.d)) +
    geom_hline(aes(yintercept = 4 / n), colour = "royalblue", linetype = "dashed") +
    labs(title = "Cook's Distance vs Index", x= "i", y = expression(D[i]))
  p2 <- ggplot(df) +
    geom_point(aes(x = index, y = dffit)) +
    geom_hline(aes(yintercept = 2 * sqrt((p+1)/n)), colour = "royalblue", linetype = "dashed") +
    geom_hline(aes(yintercept = -2 * sqrt((p+1)/n)), colour = "royalblue", linetype = "dashed") +
    labs(title = "DFFITS vs Index", x = "i", y = expression(DFFITS[i]))
  plot_grid(p1, p2, labels = "AUTO")
}
mod.influences <-
  mod.influences |>
  # create an indicator column for if any of the dfbeta measures for each beta is greater than 2/sqrt(n)
  # the second argument to if_any is a lambda function since the argument requires type function
  mutate(over.dfbetas = if_any(starts_with("dfb."), ~ .x > 2/sqrt(n)),
         over.outlier = sresid > 4,
         over.cook.4.n = cook.d > 4/n,
         over.dffits = abs(dffit) > 2 * sqrt((p+1)/n),
         over.all = over.cook.4.n | over.dffits | over.dfbetas
         )
# we can inspect this data frame to see the influential data points
infl_df <- nba |>
  mutate(over.cook.4.n = mod.influences$over.cook.4.n,
         over.outlier = mod.influences$over.outlier,
         over.dffits = mod.influences$over.dffits,
         over.dfbetas = mod.influences$over.dfbetas,
         over.all = mod.influences$over.all,) |>
  slice(which(over.all))
graph_inf(mod.influences)
```

Figure \@ref(fig:influential) shows that the dataset has no influential points using Cook's cutoff ($F_{0.5,\ p+1,\ n-p-1} =$ `r round(cook_cutoff, 3)`),
but has `r infl_df |> filter(over.cook.4.n) |> nrow()` influential points using a different cutoff ($\frac{4}{n}= `r round(4/n, 3)`$).
Alternatively, the DFFITS measure shows `r infl_df |> filter(over.dffits) |> nrow()` influential points
(with cutoff $2\sqrt{\frac{p+1}{n}}= `r round(2 * sqrt((p+1)/n), 3)`$),
while the DFBETAS measure shows $`r infl_df |> filter(over.dfbetas) |> nrow()`$ influential points
(with cutoff $\frac{2}{\sqrt{n}}= `r round(2 / sqrt(n), 3)`$).

Manually inspecting these points do not reveal any invalid data values for all predictors before or after transformations, so they can't be removed based on invalid data criteria. Because our model contains already transformed variables, we attempt to use interaction terms to eliminate or reduce these observations, with no effect. The plots used to reach this conclusion is omitted from this report for brevity, but the code to generate them can be found inside the R Markdown file next to this section.

```{r influential-treatment, eval=F}
# we can uncomment each of the following treated models with different
# interaction terms
mod.treated <-
# lm(update(mod.additional, . ~ . + tPos1:tPTS))
# lm(update(mod.additional, . ~ . + tPos1:tAST))
# lm(update(mod.additional, . ~ . + tPos1:tFvot))
# lm(update(mod.additional, . ~ . + tPos1:Age))
lm(update(mod.additional, . ~ . + tPTS:tAST))
# and etc.

# and repeat the following to check outliers, leverage and influential points
model_infl <- get_infl_measures(mod.treated)
graph_obs(model_infl)
graph_inf(model_infl)
```

```{r robust-regression, fig.cap="OLS vs IWSL fits for continuous predictors. Note the minimal difference between the slopes."}
mod.robust <- rlm(formula(mod.additional), data = nba)
plot_pred <- function(pred) {
  ggplot(nba, aes(x = eval(as.name(pred)), y = tSalary)) +
    geom_point() +
    labs(x = pred) +
    geom_smooth(method = "lm") +
    geom_smooth(method = "rlm")
}
plot_grid(plot_pred("tPTS"), plot_pred("tAST"), plot_pred("tFvot"), plot_pred("Age"))
```

We also attempt to fit a robust regression model (iteratively re-weighted least squares fits, or IWLS) using `rlm()` from `library(MASS)`, but it does not produce any qualitative difference in terms of estimates of coefficients (see Figure \@ref(fig:robust-regression)), nor does it improve residual standard error (IWLS: `r summary(mod.robust)$sigma |> round(3)` vs OLS: `r summary(mod.reduced)$sigma |> round(3)`).

In summary, we opt to leave the influential points and our model as is, since our model has no outliers, very few leverage points, and no influential points (using Cook's cutoff). 
Given the large size of the dataset ($n= `r nrow(nba)`$) and relatively few number of estimated predictors ($p=$ `r length(mod.reduced$coefficients)`), the cutoffs for DFFITS, DFBETAS, and alternate cutoff for Cook's Distance provided in lecture are too small and sensitive to determine useful influential points. 
Robust regression fits also do not provide any benefits to us, plus we don't know if we meet all the assumptions required by the robust regression method, so we will not use robust regression for our analysis.


```{r sensitivity-analysis, eval=F}
sub.nba <- nba |>
  slice(which(!mod.inflences$over.all))
mod.subset <- lm(formula(mod.reduced), data = sub.nba)
compareCoefs(mod.reduced, mod.subset)
```

\newpage

# Final Model Inference and Results

## Model Summary

```{r summary-table, results="markup"}
get_percent_increase_pred <- function(x) {
  result <- (exp(x) - 1) * 100
  result |>
    round() |>
    format(nsmall = 1) |>
    as.character() |>
    paste0("\\%")
}
get_percent_increase_intercept <- function(x) {
  x |>
    exp() |>
    round() |>
    as.character() |>
    # . = _ is to specify that the pipe goes into the second argument (_ is the native pipe placeholder)
    paste0("\\$", . = _)
}
get_exp_ci <- function(df) {
  df <- df |>
    tidyr::separate_wider_delim(ci, names = c("exp_ci_lower", "exp_ci_higher"), delim = ", ", cols_remove = F)
  pred_exp_ci <- df |>
    filter(var_type == "continuous" | (!is.na(reference_row) & !reference_row)) |>
    mutate(
      across(starts_with("exp_ci_"),
             ~ .x |>
               as.numeric() |>
               get_percent_increase_pred()
             )
      )
  intercept_exp_ci <- df |>
    filter(var_type == "intercept") |>
    mutate(
      across(starts_with("exp_ci_"),
             ~ .x |>
               as.numeric() |>
               get_percent_increase_intercept()
             )
      )
  df |>
    rows_update(pred_exp_ci, by = c("label")) |>
    rows_update(intercept_exp_ci, by = c("label")) |>
    tidyr::unite(exp_ci, starts_with("exp_ci_"), sep = ", ", na.rm = TRUE) |>
    relocate(exp_ci, .after = ci)
}

get_exp_estimate <- function(df) {
  pred_exp_estimate <- df |>
    filter(var_type == "continuous" | (!is.na(reference_row) & !reference_row)) |>
    mutate(exp_estimate = estimate |> get_percent_increase_pred())
  intercept_exp_estimate <- df |>
    filter(var_type == "intercept") |>
    mutate(exp_estimate = estimate |> get_percent_increase_intercept())
  df |>
    tibble::add_column(exp_estimate = character(length = nrow(df))) |>
    rows_update(pred_exp_estimate, by = c("label")) |>
    rows_update(intercept_exp_estimate, by = c("label")) |>
    relocate(exp_estimate, .after = estimate)
}

regression_tbl <- tbl_regression(mod.additional, intercept = T,
                                 pvalue_fun = {\(x) signif(x, 3) |> as.character()},
                                 estimate_fun = {\(x) round(x, 3) |> as.character()}) |>
  add_vif(statistic = "GVIF") |>
  modify_table_body(get_exp_ci) |>
  modify_table_body(get_exp_estimate) |>
  modify_caption("Fitted regression model summary") |>
  modify_header(label = "Predictor variables",
                # need to surround \\beta in double brackets to escape gtsummary formatting
                estimate = "$\\hat{{\\beta}}$",
                exp_estimate = "Back-transformed $\\hat{{\\beta}}$",
                # with addtl_fmt=F, need to escape %
                ci = "95\\% CI",
                exp_ci = "Back-transformed CI") |>
  modify_footnote(exp_estimate = "See below for details about the back-transforms.",
                  label = "Predictors values are per game values.")
# show_header_names(regression_tbl)
regression_tbl |>
  as_kable_extra(format = "latex", booktabs = TRUE, addtl_fmt = F) |>
  kable_styling()
```

Table \@ref(tab:summary-table) back-transformations are performed as follows:
since one-unit increase in the transformed predictors corresponds to an expected $\hat{\beta_i}$ unit increase in $log($`Salary`$)$,
holding all other predictors constant.
In other words, it's also associated with an expected increase of `Salary` by a factor of $e^{\hat{\beta_i}}$,
i.e. an increase of $(e^{\hat{\beta_i}} - 1)100\%$ [@ford_interpreting_2018].
End-points of the (95%) confidence interval is transformed and interpreted similarly, that we are 95% confident that the true expected average percentage increase lies within the interval.
This interpretation is used for the following analysis, unless otherwise noted.

## Coefficient Interpretations

```{r interpretations}
b_hat <- regression_tbl$table_body$exp_estimate
names(b_hat) <- regression_tbl$table_body$label |> names()
```

Our final regression model \@ref(eq:additional) examines how performance and demographic factors predict log-transformed NBA player salaries. The predictors include: points per game (transformed by square root), assists per game (log-transformed), fan votes (log-transformed), age, and primary position (categorical with the forwards as reference).

$\sqrt{\text{Points}}$ is the most influential predictor. A one-unit increase in $\sqrt{\text{Points}}$ is associated with an expected average $\phantom{}`r b_hat["tPTS"]`$ increase in salary (refer to Table \@ref(tab:summary-table) for the 95% confidence interval for this and all following estimates). This makes intuitive sense: scoring is a primary driver of player valuation and contract negotiation in the NBA, as it's the ultimate objective of the game: to outscore your opponent. A team needs to accumulate more points than the opposing team to win, making scoring the driving force behind all offensive strategies.

$log(\text{AST})$ is also highly significant, where each one-unit increase in the log of assists per game (i.e. base assists increase by a factor of $e \approx `r exp(1) |> round(2)`$) leads to a $\phantom{}`r b_hat["tAST"]`$ increase in salary. Assists reflect a player’s playmaking ability; it's the skill of creating offensive advantages for oneself and teammates. It's more than just passing, it involves drawing defenses in, creating open shots, and keeping the offence flowing. A good playmaker can significantly impact a team's success by engaging all players and making them feel valuable, even if they aren't scoring. Especially important for guards and point-forwards, making this an expected and meaningful result.

$log(\text{Fan Votes})$ has a smaller but still significant impact. A one-unit increase corresponds to a $\phantom{}`r b_hat["tFvot"]`$ increase in salary. This supports the idea that player popularity and marketability contribute to pay. While not as impactful as on-court performance, this reflects the entertainment aspect of the league: fan-favorite players are more likely to bring media attention, merchandise sales, and brand value to a franchise.

The coefficient for Age suggesting that for each additional year of age, salary increases by approximately $\phantom{}`r b_hat["Age"]`$. However, there are shortcomings to interpreting this coefficient estimate directly due to the complexity of age and seniority in the NBA leagues. See Section \@ref(recommendations-for-future-research) for a detailed discussion.

Our model uses SF/PF (Forwards) as the reference level, but it would be inappropriate to interpreted the intercept estimate directly, since player age is a predictor and should not take a value of 0.
Center (C) players are expected to earn $\phantom{}`r b_hat["tPos1Center"]`$ more on average compared to the forwards, point guards (PG) earn $\phantom{}`r b_hat["tPos1Point Guard"] |> gsub("-", "", x = _)`$ less,
and shooting guards (SG) earn $\phantom{}`r b_hat["tPos1Shooting Guard"] |> gsub("-", "", x = _)`$ less.

These differences reflect both team strategy and labour market dynamics. For example, centers often anchor the defense, rebound at a high rate, and are paid premiums for size and rim protection. Guards, while important, on average, are more numerous and replaceable given their smaller size and more common physical demographic, which may depress average earnings.

Overall, our results highlight that performance statistics, particularly scoring and playmaking, are the strongest predictors of salary. Age and experience also play major roles, but the relationship is more complex than a simple linear increase. Fan popularity and position add important context, revealing that salary is shaped by a combination of performance, perception, and team needs. This multifaceted structure underpins the challenges in fairly and accurately modelling player compensation in professional sports.

## Model Performance Assessment

```{r model-measures, results="markup"}
measures <- data.frame(
  Model = integer(),
  AIC = numeric(),
  BIC = numeric(),
  R2 = numeric(),
  adjR2 = numeric()
)
get_measures <- function(df, model, index) {
  if (!index %in% df$Model) {
    df |>
      add_row(
        Model = index,
        AIC = AIC(model),
        BIC = BIC(model),
        R2 = summary(model)$r.squared,
        adjR2 = summary(model)$adj.r.squared
      )
  } else {
    print(paste("Model", index, "already exists."))
    df
  }
}
measures <- get_measures(measures, nba_model, 1)
measures <- get_measures(measures, mod.transformed, 2)
measures <- get_measures(measures, mod.reduced, 3)
measures <- get_measures(measures, mod.additional, 4)
measures |> kable(digits = 3, booktabs = TRUE, format = "latex", escape = FALSE,
                  caption = "Model performance metrics.",
                  col.names = c("Model", "AIC", "BIC", "$R^2$", "$R^2_{adj}$")) |>
  kable_styling()
```

# Discussion and Conclusion

## Conclusions and Key Findings

```{r key-findings}
p_value <- regression_tbl$table_body$p.value
names(p_value) <- regression_tbl$table_body$label |> names()
```

Our analysis aimed to address the question "To what extent can NBA player salary be explained by on-court performance and position?”
We have established that there exists a strong positive correlation between NBA players’ salaries and their on-court performance,
specifically points per game and assists per game,
as seen in the high model coefficient estimates for the transformed predictors,
with a very significant p-value associated with each estimate (see Table \@ref(tab:summary-table)).
Player popularity (as measured by log of fan votes) also shows a small positive association with salary,
but the p-value for the estimate is barely significant at $p = `r p_value["tFvot"] |> round(3)`$.
Furthermore, playing positions can affect players' salaries in varying ways,
with centers generally earning more ($`r b_hat["tPos1Center"]`$) and guards earning less ($`r b_hat["tPos1Shooting Guard"] |> gsub("-", "", x = _)`$ for shooting guards and $`r b_hat["tPos1Point Guard"] |> gsub("-", "", x = _)`$ for point guards) compared to forwards, our reference group.

On the other hand, personal fouls (PF) and steals (STL) are predictors that are highly correlated with others,
making them redundant and leading to their exclusion.
Therefore, we don’t know to what extent personal fouls and steals contribute (positively or negatively) to a player’s salary.

In brief, according to our model,
the primary way for a player to improve their salary would be to improve their on-court performance in terms of their scoring and playmaking ability.
Players aiming to be more popular may see an increase to their salary as well,
but the extent of the improvement may be minor.
Additionally, players can expect an average increase in salary as they age,
or as they switch from more defensive to more offensive roles.

## Recommendations for Future Research

While the factors that we have included in our analysis affect players’ salaries,
they do not fully explain how the players are reimbursed.
Using the R-squared measure, we see that our model explains 52% of the variation in log(Salary), which leaves 48% unexplained.


For example, our model assumes that player age and $log(\text{Salary})$ are approximately linearly related for the simplicity of the model.
As seen in Section \@ref(additional-predictors),
the final model was still approximately linear,
so it was a reasonable simplification.
However, the full nature of age and career earnings in the NBA is more complex.
Typically, rookie players have a capped salary when they are 22 years and younger,
as seen in Figure \@ref(fig:salary-age).
This is due to their rookie-scale contracts signed when they first enter the league,
which usually expire after 3-4 years.
Afterwards, players receive large raises,
leading to a steep rise in earnings through their prime (roughly ages 25–30).
After that point, declining athletic performance, injuries, and team roster priorities may reduce earning power, especially for non-star players.

```{r salary-age, fig.cap="Scatterplots of Salary and log-Salary vs. Age.", fig.height=2.5}
plot_grid(
  ggplot(nba) +
    geom_point(aes(y = Salary, x = Age)) +
    labs(y = "Salary (USD)"),
  ggplot(nba) +
    geom_point(aes(y = tSalary, x = Age)) +
    labs(y = "log-Salary"))
```

Due to this complex interaction,
a better future analysis would be to use a restricted (natural) cubic spline with 1 knot for the age predictor,
or use LASSO regression to select an optimal number of knots [@nugent_very_2019].
This approach allows the model to flexibly fit separate cubic trends across distinct age ranges while maintaining smooth transitions between them to promote a better model fit.

Conversely, age may not be the most precise predictor,
as players enter the league at varying ages.
The earliest a player can be drafted into play is at the age of 19,
although many players spend additional years in college or develop in international leagues before making the leap to the NBA.
Over time, players accumulate skills, experience, and recognition through professional play.
A player’s popularity and market value are built directly over seasons played rather than how old they are.
Furthermore, NBA contracts are heavily tied to years in the league.
Therefore, “years in league” or “career experience” would serve as a more direct and accurate measure than chronological age.

The accuracy and explanatory impact of our model could also be substantially improved by incorporating key off-court and contract-related variables not present in our dataset that influence player salaries in the NBA.
For instance, while our model primarily uses on-court performance metrics (points, assists, etc.), NBA player compensation is often influenced by factors such as marketability, fan engagement, and franchise value contribution.
Including variables like social media following, merchandise/jersey sales, or All-Star voting totals would provide measurable indicators of a player’s public profile.
These aspects are particularly relevant in a league where high-visibility players can drive significant revenue beyond the court.

Contract structure is another critical missing piece.
NBA salaries are frequently shaped by collective bargaining agreements, which enforce rookie-scale contracts, max contract ceilings, and special designations like veteran extensions or supermax eligibility.
These mechanisms can lead to significant salary increases not directly tied to year-over-year performance changes.
Including a categorical variable for contract type or years in the league would help account for these structured salary jumps, instead of using restricted cubic splines for the age predictor.

# Author Contributions

Yizhe Zhao

- Rmd code used to analyze data and generate the plots, as well as the formatting for outputting the final report pdf from Rmd
- Preliminary model results section of the report

Shi Wang

- Formatting, rewriting, citations, and general proofreading of the report

Valentyn Lytvyniuk

- Proofreading, organizing in-person meeting, co-writing introduction and data description, collaborating on the data set and response/predictor variable selection

Cyre Beroncal

- Wrote initial drafts of introduction and data description sections, proposed research question
- Collaborated in selecting and interpreting initial variables used in relation to regression outputs

Jack Zhang

- Assisted in selecting and evaluating potential datasets for analysis
- Wrote the notes in the Group Teamwork Agreement Doc
- Proofreading to ensure clarity and accuracy

# Bibliography
